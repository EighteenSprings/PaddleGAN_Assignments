# ç”Ÿæˆå¯¹æŠ—ç½‘ç»œä»‹ç»



## é›¶ã€æœ¬èŠ‚å¤§çº²

![è¯¾ç¨‹å¤§çº²](./assets/Content.png)



## ä¸€ã€ç”Ÿæˆå¯¹æŠ—ç½‘ç»œæ¦‚è¿°

![GAN_Intro](./assets/GAN_Intro.png)



![GAN_History](./assets/GAN_History.png)

å­¦ä¹ è¿‡ç¨‹ä¸­åº”è¯¥æ³¨æ„çš„éƒ¨åˆ†ï¼š

1. ç½‘ç»œç»“æ„ï¼ˆâˆšï¼‰
2. æ¡ä»¶ç”Ÿæˆç½‘ç»œ
3. å›¾åƒç¿»è¯‘
4. å½’ä¸€åŒ–å’Œé™åˆ¶
5. æŸå¤±å‡½æ•°ï¼ˆâˆšï¼‰
6. è¯„ä»·æŒ‡æ ‡ï¼ˆâˆšï¼‰

âˆš ä¸ºå­¦ä¹ è¿‡ç¨‹ä¸­åº”è¯¥ç€é‡æ³¨æ„çš„éƒ¨åˆ†





## äºŒã€ç”Ÿæˆå¯¹æŠ—ç½‘ç»œåŸç†



### ç”Ÿæˆå¯¹æŠ—ç½‘ç»œä»‹ç»

ç”Ÿæˆå¯¹æŠ—ç½‘ç»œç”±ç”Ÿæˆå™¨å’Œåˆ¤åˆ«å™¨æ„æˆ

- ç”Ÿæˆå™¨ï¼šå¸Œæœ›éª—è¿‡åˆ¤åˆ«å™¨
- åˆ¤åˆ«å™¨ï¼šå¸Œæœ›é‰´åˆ«ç”Ÿæˆå™¨ç”Ÿæˆæ•°æ®æ˜¯ fake çš„

![GAN_Arch](./assets/GAN_Arch.png)

å›¾ä¸­å‡çš„å›¾ç‰‡ï¼ˆFake Imageï¼‰åˆ†æ•°è®¾ä¸º 0ï¼ŒçœŸå®å›¾ç‰‡ï¼ˆReal Imageï¼‰åˆ†æ•°è®¾ä¸º 1ã€‚

çœ‹å›¾ä¸­ç›®æ ‡å‡½æ•°
$$
\min_{G}\max_{D} = E_{x\sim P_r}[\log {D(x)}] + E_{z \sim P_z}[\log (1 - D(G(z)))]
$$
å…¶ä¸­

$ x\sim P_r $ ä»£è¡¨ $ x $ æ˜¯ä»çœŸå®æ•°æ®ä¸­å–å‡ºæ¥çš„ï¼Œå³ $ x $ æ»¡è¶³çœŸå®æ•°æ®åˆ†å¸ƒ

$ D(x) $ å³ $ x $ ä¼ å…¥åˆ¤åˆ«å™¨ï¼ˆDiscriminatorï¼‰å¾—åˆ°çš„åˆ†æ•°ï¼Œè¿™é‡Œæˆ‘ä»¬ä¼šå– logï¼Œå¾—åˆ° $ \log {D(x)} $

$ x \sim P_z $ ä»£è¡¨ $ z $ æ˜¯ä»éšæœºå™ªå£°ä¸­å–å‡ºæ¥çš„ï¼Œå³è¿™é‡Œå¾—åˆ°çš„ $ z $ æ»¡è¶³éšæœºå™ªå£°çš„åˆ†å¸ƒ

$ D(G(z)) $ ä»£è¡¨ä»éšæœºå™ªå£°åˆ†å¸ƒä¸­é‡‡æ ·å¾—åˆ°çš„ $ z $ ï¼Œé€šè¿‡ç”Ÿæˆå™¨ï¼ˆGeneratorï¼‰ï¼Œå¾—åˆ°ç”Ÿæˆå›¾ç‰‡ï¼ˆFake Imageï¼‰ï¼Œå†é€šè¿‡åˆ¤åˆ«å™¨ï¼Œæœ€åå¾—åˆ°çš„åˆ†æ•°ã€‚

**ç”Ÿæˆå™¨**

å¯¹äº ç”Ÿæˆå™¨ï¼Œæˆ‘ä»¬å…ˆçœ‹ $ \min_{G} $

å› ä¸º

â€‹	é€šè¿‡ $ z $ ç”Ÿæˆçš„å›¾åƒæˆ‘ä»¬å¸Œæœ›å®ƒæ¥è¿‘çœŸå®æ•°æ®

æ‰€ä»¥

â€‹	$ z $ ç»è¿‡åˆ¤åˆ«å™¨å¾—åˆ°çš„åˆ†æ•°æˆ‘ä»¬å¸Œæœ›å®ƒèƒ½è¶Šå¤§è¶Šå¥½

â€‹	åŒæ—¶æ¥è¿‘çœŸå®æ•°æ®é€šè¿‡åˆ¤åˆ«å™¨å¾—åˆ°çš„åˆ†æ•°ï¼Œå³ä¸ $ D(x) $ è¶Šæ¥è¿‘è¶Šå¥½ã€‚ 

â€‹	å³è¯¾ä¸­è€å¸ˆè¯´çš„ â€ç”Ÿæˆçš„å›¾ç‰‡å’ŒçœŸå®çš„å›¾ç‰‡å‡ ä¹ä¸€æ ·â€œ

**åˆ¤åˆ«å™¨**

å¯¹äº åˆ¤åˆ«å™¨ï¼Œæˆ‘ä»¬çœ‹ $ \min_D $

å› ä¸º

â€‹	æˆ‘ä»¬å¸Œæœ›é€šè¿‡ $ z $ ç”Ÿæˆçš„å›¾åƒèƒ½è¢«é‰´åˆ«å™¨åˆ¤æ–­å‡ºæ¥

æ‰€ä»¥

â€‹	$ z $ ç»è¿‡åˆ¤åˆ«å™¨å¾—åˆ°çš„åˆ†æ•°æˆ‘ä»¬å¸Œæœ›å®ƒè¶Šå°è¶Šå¥½

â€‹	åŒæ—¶å¾—åˆ°çš„åˆ†æ•° $ D(z) $ è¦ä¸çœŸå®æ•°æ®é€šè¿‡åˆ¤åˆ«å™¨å¾—åˆ°çš„åˆ†æ•° $ D(x) $ ç›¸å·®è¶Šå¤§è¶Šå¥½

â€‹	å³ â€ç”Ÿæˆçš„å›¾ç‰‡å’ŒçœŸå®çš„å›¾ç‰‡åªè¦æœ‰ä¸€ç‚¹ç‚¹ä¸åŒï¼Œå°±ä¼šè¢«åˆ¤æ–­å‡ºæ¥â€œ



### ç”Ÿæˆå¯¹æŠ—ç½‘ç»œçš„è¿­ä»£è¿‡ç¨‹



![GAN_Autocoder](./assets/GAN_Autoencoder.png)

**Autocoder**

åŸå›¾åƒé€šè¿‡ Encoder ç¼–ç ä¸ºå›ºå®šç»´åº¦çš„ vectorï¼Œå†é€šè¿‡ Decoder è§£ç ä¸ºè¾“å…¥å›¾åƒå°ºåº¦ç›¸åŒçš„å›¾ç‰‡ï¼Œå¹¶é€šè¿‡è®¡ç®—è¯¥å›¾ç‰‡å’ŒåŸå›¾çš„ L2 Loss æ¥ä½¿å¾—ç”Ÿæˆçš„å›¾å°½å¯èƒ½ä¸åŸå›¾æ¥è¿‘ã€‚

è¿™æ ·å¾—åˆ°çš„ç½‘ç»œï¼Œæˆ‘ä»¬å–å‡ºå…¶ä¸­ Decoder éƒ¨åˆ†ï¼Œé€šè¿‡è°ƒæ•´ vector èƒ½ç”Ÿæˆå›¾ç‰‡ã€‚

![GAN_diff](./assets/GAN_diff.png)



### ç”Ÿæˆå¯¹æŠ—ç½‘ç»œçš„ä¸€ç‚¹ç‚¹ç†è®º

![GAN_Simple_Theory](./assets/GAN_Simple_Theory.png)

é€šè¿‡é‡‡æ · [0, 1] ä¹‹é—´çš„å‡åŒ€åˆ†å¸ƒï¼Œå¾—åˆ°ä¸€ä¸ªå‘é‡ï¼ˆvectorï¼‰ï¼Œç”Ÿæˆå™¨æ ¹æ®è¿™ä¸ªå‘é‡ï¼Œå»æ‹ŸåˆçœŸå®åˆ†å¸ƒï¼Œä»è€Œå¾—åˆ°å’Œç›®æ ‡å›¾åƒæ¥è¿‘çš„ç”Ÿæˆå›¾åƒ



![GAN_Simple_Theory3](./assets/GAN_Simple_Theory3.png)

ä¸Šå›¾æ˜¯ GAN è®­ç»ƒè¿‡ç¨‹çš„å¯è§†åŒ–ï¼Œå¯ä»¥çœ‹åˆ°éšç€å‚æ•°çš„æ›´æ–°ï¼Œæˆ‘ä»¬é€šè¿‡ç”Ÿæˆå™¨æ‹Ÿåˆå‡ºçš„æ•°æ®åˆ†å¸ƒä¼šé€æ¸å‘ç€çœŸå®æ•°æ®æ¥è¿‘ï¼Œå¹¶ä¸”åˆ¤åˆ«å™¨çš„åˆ†ç±»æ•ˆæœä¼šè¶Šæ¥è¶Šå·®å¹¶æœ€ç»ˆä¸º 0.5ï¼ˆ 1 ä¸ºçœŸå®æ•°æ®å¾—åˆ†ï¼Œ0 ä¸ºç”Ÿæˆæ•°æ®å¾—åˆ†ï¼‰ï¼Œå³æ— æ³•æ­£ç¡®åˆ¤æ–­ã€‚

![GAN_Simple_Theory4](./assets/GAN_Simple_Theory4.png)

åˆ¤åˆ«å™¨è®­ç»ƒå¯ä»¥çœ‹ä½œäºŒåˆ†ç±»é—®é¢˜ï¼Œå…¶ä¸­  $ \tilde{x} $ ä¸ºéšæœºå™ªå£° $ z $ é€šè¿‡ç”Ÿæˆå™¨å¾—åˆ°çš„ç”Ÿæˆå›¾åƒ



![GAN_Simple_Theory5](./assets/GAN_Simple_Theory5.png)

å›¾ä¸­çº¢çº¿éƒ¨åˆ†ä¸ºç”Ÿæˆå™¨æ— å…³é¡¹ï¼Œå³çœŸå®å›¾ç‰‡é€šè¿‡åˆ¤åˆ«å™¨çš„åˆ†æ•°ï¼ˆé‚£æˆ‘å‰é¢å°±è¯´é”™äº†ï¼Œ$ \max_{G} $ å®é™…ä¸Šåªè€ƒè™‘åˆ°äº†ç”Ÿæˆå›¾åƒåœ¨åˆ¤åˆ«å™¨çš„åˆ†æ•°ï¼Œè€ŒçœŸå®æ•°æ®è¿™å—å¹¶æ²¡æœ‰è€ƒè™‘åˆ° ğŸ˜”ï¼‰

å…¶ä¸­ç”Ÿæˆå›¾åƒï¼ˆfake imageï¼‰å› ä¸ºæœŸæœ›å®ƒèƒ½æ¬ºéª—åˆ¤åˆ«å™¨è‡ªå·±æ˜¯â€œçœŸå®å›¾åƒâ€œï¼Œæ‰€ä»¥å®ƒçš„ label åº”è¯¥ä¸º 1ã€‚



## ä¸‰ã€DCGAN ä»£ç å®è·µ



![GAN_DCGAN](./assets/GAN_DCGAN.png)

ä¸Šé¢æ˜¯è¾ƒç®€å•çš„ GAN ç½‘ç»œä»£ç æ¼”ç¤ºï¼Œä»…ä½œç¤ºä¾‹



![GAN_DCGAN2](./assets/GAN_DCGAN2.png)



DCGAN = Deep Convolutional GANï¼ˆæ·±åº¦å·ç§¯ GANï¼‰

å·¦è¾¹å¯èƒ½çœ‹ä¸æ¸…æ¥šï¼Œæ˜¯ ConvTransposeï¼Œå³å¯ä»¥çœ‹ä½œå·ç§¯çš„é€†æ“ä½œï¼Œå³ [è½¬ç½®å·ç§¯][]

æ”¹è¿›ï¼š

- å·ç§¯ä»£æ›¿å…¨è¿æ¥
- ä½“æ£€ BatchNormï¼Œé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸ã€æ¶ˆå¤±ã€
- ç”Ÿæˆå™¨ ReLU
- åˆ¤åˆ«å™¨ä½¿ç”¨ LeakyReluï¼ˆ0.2ï¼‰



**DCGAN** ä»£ç ä»‹ç»

æˆ‘ä»¬çš„ [æœ¬è¯¾ä½œä¸š][] å°±æ˜¯é€šè¿‡ä¿®æ”¹ DCGAN çš„ä»£ç æ¥å®ç° LSGANï¼Œé‚£åœ¨è¿™ä¹‹å‰æˆ‘ä»¬å…ˆçœ‹ä¸‹ DCGAN çš„ä»£ç 

ä½¿ç”¨çš„æ•°æ®é›†æ˜¯ MNISTï¼Œæ‰‹å†™æ•°å­—

![MNIST](./assets/MNIST_plot.png)

### æ•°æ®é¢„å¤„ç†

çœ‹å®Œæ•°æ®æ ·å¼ä¹‹åï¼Œæˆ‘ä»¬ä¼šå¯¹æ•°æ®è¿›è¡Œä¸€ä¸ªé¢„å¤„ç†

```python
dataset = paddle.vision.datasets.MNIST(mode='train', 
                                        transform=transforms.Compose([
                                        # resize ->(32,32)
                                        transforms.Resize((32,32)),
                                        # å½’ä¸€åŒ–åˆ°-1~1
                                        transforms.Normalize([127.5], [127.5])
                                    ]))

dataloader = paddle.io.DataLoader(dataset, batch_size=32,
                                  shuffle=True, num_workers=4)
```

å…ˆå¯¹æ•°æ®è¿›è¡Œä¸€ä¸ªç¼©æ”¾ï¼Œä½¿å¾—æ‰€å›¾åƒéƒ½å˜æˆ (32, 32) å°ºå¯¸çš„å›¾ç‰‡ï¼Œå› ä¸ºæ•°å­—è¯†åˆ«å¯¹å›¾åƒæ¸…æ™°åº¦è¦æ±‚ä¸é«˜ï¼Œæ‰€ä»¥ 32 è¶³ä»¥

å†å°±æ˜¯å°†å›¾åƒæ•°æ®å½’ä¸€åŒ–åˆ° [0, 1] ä¹‹é—´ï¼Œæ›´å¥½æ”¶æ•›ï¼ˆå¯ä»¥çœ‹è¿™ç¯‡ [å½’ä¸€åŒ–][] æ–‡ç« ï¼Œé‡Œé¢æ˜¯æˆ‘æ¯”è¾ƒèµåŒçš„ä½¿ç”¨å½’ä¸€åŒ–åŸå› ï¼‰

### å‚æ•°åˆå§‹åŒ–

```python
#å‚æ•°åˆå§‹åŒ–çš„æ¨¡å—
@paddle.no_grad()
def normal_(x, mean=0., std=1.):
    temp_value = paddle.normal(mean, std, shape=x.shape)
    x.set_value(temp_value)
    return x

@paddle.no_grad()
def uniform_(x, a=-1., b=1.):
    temp_value = paddle.uniform(min=a, max=b, shape=x.shape)
    x.set_value(temp_value)
    return x

@paddle.no_grad()
def constant_(x, value):
    temp_value = paddle.full(x.shape, value, x.dtype)
    x.set_value(temp_value)
    return x

def weights_init(m):
    classname = m.__class__.__name__
    if hasattr(m, 'weight') and classname.find('Conv') != -1:
        normal_(m.weight, 0.0, 0.02)
    elif classname.find('BatchNorm') != -1:
        normal_(m.weight, 1.0, 0.02)
        constant_(m.bias, 0)
```

è¯¾ä¸­ç»•è¿‡äº†è¿™ä¸ªéƒ¨åˆ†ï¼Œå®é™…ä¸Šå‚æ•°åˆå§‹åŒ–æ˜¯æ ¹æ®è®ºæ–‡ä¸­çš„ç»éªŒæ•°å€¼æ¥çš„ï¼Œæ ¹æ® PyTorch å®˜æ–¹çš„ä¸€ç¯‡æ•™ç¨‹è®²åˆ°çš„

> From the DCGAN paper, the authors specify that all model weights shall be randomly initialized from a Normal distribution with mean=0, stdev=0.02. The `weights_init` function takes an initialized model as input and reinitializes all convolutional, convolutional-transpose, and batch normalization layers to meet this criteria. This function is applied to the models immediately after initialization.

å³æ¨¡å‹ä¸­çš„å·ç§¯ï¼ˆConv2ï¼‰ã€åå·ç§¯ï¼ˆConv2DTransposeï¼‰çš„å‚æ•°éƒ½ç”¨ 0 å‡å€¼ 0.02 æ–¹å·®çš„é«˜æ–¯åˆ†å¸ƒåˆå§‹åŒ–



### å®šä¹‰ç”Ÿæˆå™¨

```python
# Generator Code
class Generator(nn.Layer):
    def __init__(self, ):
        super(Generator, self).__init__()
        self.gen = nn.Sequential(
            # input is Z, [B, 100, 1, 1] -> [B, 64 * 4, 4, 4]
            nn.Conv2DTranspose(100, 64 * 4, 4, 1, 0, bias_attr=False),
            nn.BatchNorm2D(64 * 4),
            nn.ReLU(True),
            # state size. [B, 64 * 4, 4, 4] -> [B, 64 * 2, 8, 8]
            nn.Conv2DTranspose(64 * 4, 64 * 2, 4, 2, 1, bias_attr=False),
            nn.BatchNorm2D(64 * 2),
            nn.ReLU(True),
            # state size. [B, 64 * 2, 8, 8] -> [B, 64, 16, 16]
            nn.Conv2DTranspose( 64 * 2, 64, 4, 2, 1, bias_attr=False),
            nn.BatchNorm2D(64),
            nn.ReLU(True),
            # state size. [B, 64, 16, 16] -> [B, 1, 32, 32]
            nn.Conv2DTranspose( 64, 1, 4, 2, 1, bias_attr=False),
            nn.Tanh()
        )

    def forward(self, x):
        return self.gen(x)
```

[Conv2DTranspose][] çš„å‚æ•°å¯ä»¥ç‚¹å‡»é“¾æ¥çœ‹å…·ä½“ä½œç”¨

![Conv2DTranspose](./assets/Conv2DTranspose.png)

å…³äºè¾“å‡ºçš„å›¾åƒå°ºå¯¸å¦‚ä½•å˜åŒ–
$$
\begin{align*}
& W_{out} = (W_{in} - 1) \times \text{stride}[1] - 2 \times \text{padding}[1] + \text{dilation}[1]
                        \times (\text{kernel_size}[1] - 1) + \text{output_padding}[1] + 1 \\
& H_{out} = (H_{in} - 1) \times \text{stride}[0] - 2 \times \text{padding}[0] + \text{dilation}[0] \times (\text{kernel_size}[0] - 1) + \text{output_padding}[0] + 1 
\end{align*}
$$



### å®šä¹‰åˆ¤åˆ«å™¨

```python
class Discriminator(nn.Layer):
    def __init__(self,):
        super(Discriminator, self).__init__()
        self.dis = nn.Sequential(

            # input [B, 1, 32, 32] -> [B, 64, 16, 16]
            nn.Conv2D(1, 64, 4, 2, 1, bias_attr=False),
            nn.LeakyReLU(0.2),

            # state size. [B, 64, 16, 16] -> [B, 128, 8, 8]
            nn.Conv2D(64, 64 * 2, 4, 2, 1, bias_attr=False),
            nn.BatchNorm2D(64 * 2),
            nn.LeakyReLU(0.2),

            # state size. [B, 128, 8, 8] -> [B, 256, 4, 4]
            nn.Conv2D(64 * 2, 64 * 4, 4, 2, 1, bias_attr=False),
            nn.BatchNorm2D(64 * 4),
            nn.LeakyReLU(0.2),

            # state size. [B, 256, 4, 4] -> [B, 1, 1, 1]
            nn.Conv2D(64 * 4, 1, 4, 1, 0, bias_attr=False),
            # è¿™é‡Œä¸ºéœ€è¦æ”¹å˜çš„åœ°æ–¹
            nn.Sigmoid()
        )

    def forward(self, x):
        return self.dis(x)
```



### å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨

```python
loss = nn.BCELoss()

# Create batch of latent vectors that we will use to visualize
#  the progression of the generator
fixed_noise = paddle.randn([32, 100, 1, 1], dtype='float32')

# Establish convention for real and fake labels during training
real_label = 1.
fake_label = 0.

# Setup Adam optimizers for both G and D
optimizerD = optim.Adam(parameters=netD.parameters(), learning_rate=0.0002, beta1=0.5, beta2=0.999)
optimizerG = optim.Adam(parameters=netG.parameters(), learning_rate=0.0002, beta1=0.5, beta2=0.999)
```





### è®­ç»ƒè¿‡ç¨‹

```python
losses = [[], []]
#plt.ion()
now = 0
for pass_id in range(100):
    for batch_id, (data, target) in enumerate(dataloader):
        ############################
        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))
        ###########################

        optimizerD.clear_grad()
        real_img = data
        bs_size = real_img.shape[0]
        label = paddle.full((bs_size, 1, 1, 1), real_label, dtype='float32')
        real_out = netD(real_img)
        errD_real = loss(real_out, label)
        errD_real.backward()

        noise = paddle.randn([bs_size, 100, 1, 1], 'float32')
        fake_img = netG(noise)
        label = paddle.full((bs_size, 1, 1, 1), fake_label, dtype='float32')
        fake_out = netD(fake_img.detach())
        errD_fake = loss(fake_out,label)
        errD_fake.backward()
        optimizerD.step()
        optimizerD.clear_grad()

        errD = errD_real + errD_fake
        losses[0].append(errD.numpy()[0])

        ############################
        # (2) Update G network: maximize log(D(G(z)))
        ###########################
        optimizerG.clear_grad()
        noise = paddle.randn([bs_size, 100, 1, 1],'float32')
        fake = netG(noise)
        label = paddle.full((bs_size, 1, 1, 1), real_label, dtype=np.float32,)
        output = netD(fake)
        errG = loss(output,label)
        errG.backward()
        optimizerG.step()
        optimizerG.clear_grad()

        losses[1].append(errG.numpy()[0])


        ############################
        # visualize
        ###########################
        if batch_id % 100 == 0:
            generated_image = netG(noise).numpy()
            imgs = []
            plt.figure(figsize=(15,15))
            try:
                for i in range(10):
                    image = generated_image[i].transpose()
                    image = np.where(image > 0, image, 0)
                    image = image.transpose((1,0,2))
                    plt.subplot(10, 10, i + 1)
                    
                    plt.imshow(image[...,0], vmin=-1, vmax=1)
                    plt.axis('off')
                    plt.xticks([])
                    plt.yticks([])
                    plt.subplots_adjust(wspace=0.1, hspace=0.1)
                msg = 'Epoch ID={0} Batch ID={1} \n\n D-Loss={2} G-Loss={3}'.format(pass_id, batch_id, errD.numpy()[0], errG.numpy()[0])
                print(msg)
                plt.suptitle(msg,fontsize=20)
                plt.draw()
                plt.savefig('{}/{:04d}_{:04d}.png'.format('work', pass_id, batch_id), bbox_inches='tight')
                plt.pause(0.01)
            except IOError:
                print(IOError)
    paddle.save(netG.state_dict(), "work/generator.params")
```



## å››ã€PaddleGAN æ¶æ„

![PaddleGAN_Arch](./assets/PaddleGAN_Arch.png)

ä»¥ä¸Šæ˜¯æ¡†æ¶ä»‹ç»

![PaddleGAN_Intro](assets/PaddleGAN_Intro.png)

ä»¥ä¸Šæ˜¯å…¨æ™¯å›¾



## äº”ã€ç•ªå¤–

åœ¨æ•´ä¸ªæ·±åº¦å­¦ä¹ æ¶æ„ä¸­ï¼Œæˆ‘ä»¬å·²ç»å­¦ä¹ äº† GAN çš„ç®€å•æ¶æ„ï¼Œè¿™é‡Œä¸»è¦å…³æ³¨ä¸‹ GAN çš„ Loss å’Œ Metrics

### Loss

- GANLoss
- PerceptualLoss
- PixelLoss



#### Metrics

- FID
- PSNR
- SSIM





[æœ¬è¯¾ä½œä¸š]: https://aistudio.baidu.com/aistudio/projectdetail/1816341?pV=348099	"DCGAN ä¿®æ”¹ä¸º LSGAN"

[è½¬ç½®å·ç§¯]: https://blog.csdn.net/tsyccnh/article/details/87357447	"è½¬ç½®å·ç§¯ä»‹ç»"
[å½’ä¸€åŒ–]: https://www.zhihu.com/question/20455227/answer/197897298	"ç‰¹å¾å·¥ç¨‹ä¸­çš„ã€Œå½’ä¸€åŒ–ã€æœ‰ä»€ä¹ˆä½œç”¨ï¼Ÿ - å¿†è‡»çš„å›ç­” - çŸ¥ä¹"
[PyTorch_DCGAN_Tutorial]: https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html	"DCGAN TUTORIAL"

[Conv2DTranspose]: https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/nn/layer/conv/Conv2DTranspose_cn.html	"Conv2DTranspose çš„æ–‡æ¡£"

